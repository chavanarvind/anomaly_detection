import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score


def remove_low_variance_columns(df, threshold=0.01, timestamp_col='timestamp'):
    # Identify columns to calculate variance on, excluding the timestamp column
    cols_to_check = df.columns[df.columns != timestamp_col]
    low_variance_cols = df[cols_to_check].columns[df[cols_to_check].var() < threshold]

    print(f"Low variance columns identified for removal: {low_variance_cols.tolist()}")

    # Return the DataFrame without low variance columns, keeping the timestamp column
    return df.drop(columns=low_variance_cols)


def train_isolation_forest(X, contamination):
    model = IsolationForest(contamination=contamination, random_state=42)
    model.fit(X)
    print("Isolation Forest model trained.")
    return model


def dynamic_anomaly_detection(df, window_size=30, timestamp_col='timestamp'):
    # Remove low variance columns
    df_cleaned = remove_low_variance_columns(df, timestamp_col=timestamp_col)

    # Ensure there are enough rows for windows
    if len(df_cleaned) < window_size:
        raise ValueError("DataFrame is too small for the specified window size.")

    # Sort by timestamp
    df_sorted = df_cleaned.sort_values(by=timestamp_col)

    # Initialize anomaly labels and silhouette scores
    anomaly_labels = np.zeros(len(df_sorted))
    silhouette_scores = []

    # Scaling features (excluding timestamp)
    scaler = StandardScaler()
    features = df_sorted.drop(columns=[timestamp_col])
    scaled_features = scaler.fit_transform(features)

    print("Features scaled.")

    # Train Isolation Forest on scaled features
    model = train_isolation_forest(scaled_features, contamination=0.1)

    # Predict anomalies on scaled features
    for start in range(0, len(df_sorted) - window_size + 1):
        window = scaled_features[start:start + window_size]
        predictions = model.predict(window)  # Predictions are -1 (anomaly) or 1 (normal)
        anomaly_labels[start:start + window_size] = predictions

        # Calculate silhouette score
        if len(set(predictions)) > 1:  # At least two distinct classes (normal and anomalies)
            score = silhouette_score(window, predictions)
            silhouette_scores.append(score)
            print(f"Silhouette score calculated for window {start}: {score}")
        else:
            silhouette_scores.append(np.nan)  # Not enough clusters to compute score
            print(f"Silhouette score not calculated for window {start}: only one cluster found.")

        # Dynamic plotting for each window
        plt.figure(figsize=(12, 6))

        # Ensure we only plot the current window's data and the anomalies
        window_anomalies = anomaly_labels[start:start + window_size]
        current_time = df_sorted[timestamp_col].iloc[start:start + window_size]

        if len(features.columns) == 1:  # Single feature case
            plt.plot(current_time, features.iloc[start:start + window_size, 0],
                     label=features.columns[0], color='blue', alpha=0.5)
            plt.scatter(current_time[window_anomalies == -1],
                        features.iloc[start:start + window_size, 0][window_anomalies == -1],
                        color='red', label='Anomalies', marker='o')
            plt.title('Anomaly Detection (Single Feature)')
            plt.xlabel('Time')
            plt.ylabel(features.columns[0])  # Use feature name
        else:  # Multiple feature case
            for i, col in enumerate(features.columns):
                plt.plot(current_time, features.iloc[start:start + window_size, i],
                         label=col, alpha=0.5)
            plt.scatter(current_time[window_anomalies == -1],
                        features.iloc[start:start + window_size][window_anomalies == -1].values,
                        color='red', label='Anomalies', marker='o')
            plt.title('Anomaly Detection (Multiple Features)')
            plt.xlabel('Time')
            plt.ylabel('Feature Values')

        plt.legend()
        plt.grid()
        plt.show()

    # Mark anomalies in the original DataFrame
    df_sorted['anomaly'] = 0  # Initialize the anomaly column
    df_sorted.loc[anomaly_labels == -1, 'anomaly'] = 1  # Mark anomalies with 1

    print("Anomalies marked in the DataFrame.")

    return anomaly_labels, silhouette_scores


# Create a dummy DataFrame for testing with a single feature
np.random.seed(42)
timestamp = pd.date_range(start='2023-01-01', periods=2000, freq='T')
data = {
    'timestamp': timestamp,
    'feature1': np.random.rand(2000),
    # Uncomment the next line to test with multiple features
    # 'feature2': np.random.rand(2000) * 10,
    # 'feature3': np.random.normal(0, 1, 2000),
}

df = pd.DataFrame(data)

# Run the anomaly detection
anomaly_labels, silhouette_scores = dynamic_anomaly_detection(df, window_size=30)

# Display silhouette scores
print(f"Silhouette Scores: {silhouette_scores}")
